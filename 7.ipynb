{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Natural Language Toolkit (NLTK) library\n",
    "# NLTK is a powerful Python library for natural language processing tasks\n",
    "import nltk\n",
    "nltk.download('punkt', download_dir='./nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the opening line from Jane Austen's Pride and Prejudice\n",
    "# The text will be used for natural language processing examples\n",
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune,  must be in want of a wife.\" \n",
    "text = text.lower() \n",
    "print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the opening line from Jane Austen's Pride and Prejudice (1813)\n",
    "# The text will be used as a sample for natural language processing tasks\n",
    "# The sentence is a famous example of irony and social commentary in literature\n",
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune,  must be in want of a wife.\" \n",
    "text = text.lower() \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172250e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the string module which provides constants for ASCII characters\n",
    "# This module is particularly useful for handling punctuation and other special characters\n",
    "import string \n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all punctuation marks from the text using string.punctuation\n",
    "# This creates a clean version of the text without any special characters\n",
    "text_p = \"\".join([char for char in text if char not in string.punctuation]); print(text_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Natural Language Toolkit (NLTK) library\n",
    "# NLTK is a comprehensive Python library for natural language processing\n",
    "# It provides tools for tokenization, stemming, tagging, parsing, and more\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071a6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word_tokenize and sent_tokenize from NLTK's tokenize module\n",
    "# word_tokenize splits text into individual words\n",
    "# sent_tokenize splits text into sentences\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the cleaned text (text_p) into individual words using NLTK's word_tokenize\n",
    "# This splits the text into a list of words, handling contractions and special cases\n",
    "words = word_tokenize(text_p)\n",
    "words1 = sent_tokenize(text_p)\n",
    "print(words)\n",
    "print(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK library for natural language processing tasks\n",
    "import nltk\n",
    "\n",
    "# Import word_tokenize and sent_tokenize for splitting text into words and sentences\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Import stopwords to remove common words that don't add meaning (e.g., 'the', 'is', 'at')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import string module for handling punctuation and special characters\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample text\n",
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\n",
    "\n",
    "# Remove punctuation\n",
    "text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "# Tokenize\n",
    "words = word_tokenize(text_p)\n",
    "sentences = sent_tokenize(text_p)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "# Print results\n",
    "print(\"Words:\", words)\n",
    "print(\"Filtered Words:\", filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49835763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out stopwords from the tokenized words list\n",
    "# This creates a new list containing only meaningful words by removing common words like 'the', 'is', 'at'\n",
    "# The list comprehension checks each word against the stop_words set and only keeps non-stopwords\n",
    "filtered_words = [word for word in words if word not in stop_words] \n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PorterStemmer from NLTK's stem package\n",
    "# PorterStemmer is a stemming algorithm that reduces words to their root form\n",
    "# For example: \"running\" -> \"run\", \"jumps\" -> \"jump\"\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "porter = PorterStemmer() \n",
    "stemmed = [porter.stem(word) for word in filtered_words] \n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Natural Language Toolkit (NLTK) library\n",
    "# NLTK is a leading platform for building Python programs to work with human language data\n",
    "# It provides easy-to-use interfaces to over 50 corpora and lexical resources\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pos_tag from NLTK's tag package\n",
    "# pos_tag is a part-of-speech tagger that assigns grammatical categories to words\n",
    "# For example: \"run\" -> \"VB\" (verb), \"cat\" -> \"NN\" (noun)\n",
    "from nltk import pos_tag\n",
    "pos = pos_tag(filtered_words) \n",
    "print(pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
